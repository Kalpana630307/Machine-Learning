{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPK78RZCwHtBape5gOI6OzW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":[],"metadata":{"id":"9l2RlrOcWOLv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ez9ve_SKV9JD","executionInfo":{"status":"ok","timestamp":1743745901343,"user_tz":-330,"elapsed":511,"user":{"displayName":"kalpanakumari uppalapati","userId":"03332832456954989276"}},"outputId":"74d24270-6b75-4d6d-a8f8-ac3f5f178766"},"outputs":[{"output_type":"stream","name":"stdout","text":["Decision Tree:\n","{'Weather': {'Overcast': 'Yes', 'Rainy': {'Windy': {False: 'Yes', True: 'No'}}, 'Sunny': {'Temperature': {'Hot': 'No', 'Mild': 'Yes'}}}}\n","Accuracy: 0.6666666666666666\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import random\n","\n","# Define the dataset\n","data = {\n","    'Weather': ['Sunny', 'Sunny', 'Overcast', 'Rainy', 'Rainy', 'Rainy', 'Overcast', 'Sunny', 'Sunny',\n","                'Rainy', 'Sunny', 'Overcast', 'Overcast', 'Rainy'],\n","    'Temperature': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild',\n","                    'Mild', 'Hot', 'Mild'],\n","    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal',\n","                 'Normal', 'Normal', 'High', 'Normal', 'High'],\n","    'Windy': [False, True, False, False, False, True, True, False, False, False, True, True, False,\n","              True],\n","    'Play Tennis': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes',\n","                    'No']\n","}\n","\n","df = pd.DataFrame(data)\n","\n","# Function to calculate entropy\n","def entropy(target_col):\n","    elements, counts = np.unique(target_col, return_counts=True)\n","    entropy_val = -np.sum([(counts[i] / np.sum(counts)) * np.log2(counts[i] / np.sum(counts)) for\n","                            i in range(len(elements))])\n","    return entropy_val\n","\n","# Function to calculate information gain\n","def information_gain(data, split_attribute_name, target_name):\n","    total_entropy = entropy(data[target_name])\n","    vals, counts = np.unique(data[split_attribute_name], return_counts=True)\n","    weighted_entropy = np.sum([(counts[i] / np.sum(counts)) *\n","                               entropy(data.where(data[split_attribute_name] == vals[i]).dropna()[target_name]) for\n","                               i in range(len(vals))])\n","    information_gain_val = total_entropy - weighted_entropy\n","    return information_gain_val\n","\n","# Function for ID3 Algorithm (recursive decision tree construction)\n","def id3_algorithm(data, original_data, features, target_attribute_name, parent_node_class):\n","    # Base cases\n","    if len(np.unique(data[target_attribute_name])) <= 1:\n","        return np.unique(data[target_attribute_name])[0]\n","    elif len(data) == 0:\n","        return np.unique(original_data[target_attribute_name])[np.argmax(\n","            np.unique(original_data[target_attribute_name], return_counts=True)[1])]\n","    elif len(features) == 0:\n","        return parent_node_class\n","    else:\n","        # Set the parent node class to the majority class\n","        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(\n","            np.unique(data[target_attribute_name], return_counts=True)[1])]\n","\n","        # Calculate information gain for all features\n","        item_values = [information_gain(data, feature, target_attribute_name) for feature in features]\n","        best_feature_index = np.argmax(item_values)\n","        best_feature = features[best_feature_index]\n","\n","        # Create the tree with the best feature as the root node\n","        tree = {best_feature: {}}\n","\n","        # Remove the best feature from the list of features to consider for further splits\n","        features = [i for i in features if i != best_feature]\n","\n","        # For each value of the best feature, create subtrees\n","        for value in np.unique(data[best_feature]):\n","            sub_data = data.where(data[best_feature] == value).dropna()\n","            subtree = id3_algorithm(sub_data, original_data, features, target_attribute_name, parent_node_class)\n","            tree[best_feature][value] = subtree\n","        return tree\n","\n","# Function to make predictions\n","def predict(query, tree, default='Yes'):\n","    for key in query.keys():\n","        if key in tree.keys():\n","            try:\n","                result = tree[key][query[key]]\n","            except:\n","                return default\n","            if isinstance(result, dict):\n","                return predict(query, result, default)\n","            else:\n","                return result\n","    return default\n","\n","# Function to split the data into train and test sets\n","def train_test_split(df, test_size):\n","    if isinstance(test_size, float):\n","        test_size = round(test_size * len(df))\n","    indices = df.index.tolist()\n","    test_indices = random.sample(population=indices, k=test_size)\n","    test_df = df.loc[test_indices]\n","    train_df = df.drop(test_indices)\n","    return train_df, test_df\n","\n","# Function to train the model using ID3 algorithm\n","def fit(df, target_attribute_name, features):\n","    return id3_algorithm(df, df, features, target_attribute_name, None)\n","\n","# Function to calculate the accuracy of the model\n","def get_accuracy(df, tree, target_attribute_name):\n","    df[\"classification\"] = df.apply(lambda row: predict(row, tree), axis=1)\n","    df[\"classification_correct\"] = df[\"classification\"] == df[target_attribute_name]\n","    accuracy = df[\"classification_correct\"].mean()\n","    return accuracy\n","\n","# Split the data into training and testing sets\n","train_data, test_data = train_test_split(df, test_size=0.2)\n","\n","# Train the decision tree on the training data\n","tree = fit(train_data, 'Play Tennis', ['Weather', 'Temperature', 'Humidity', 'Windy'])\n","\n","# Calculate the accuracy of the decision tree on the test data\n","accuracy = get_accuracy(test_data, tree, 'Play Tennis')\n","\n","# Print the decision tree and accuracy\n","print(\"Decision Tree:\")\n","print(tree)\n","print(\"Accuracy:\", accuracy)\n"]}]}